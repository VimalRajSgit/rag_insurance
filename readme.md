# ğŸš— Auto Insurance RAG System

A sophisticated **Retrieval-Augmented Generation (RAG)** system for auto insurance analysis, powered by **ChromaDB**, **Sentence Transformers**, and **Groq LLM**. This system processes insurance claims data and provides intelligent, data-driven insights through a beautiful Streamlit interface.

## ğŸŒŸ Features

- **ğŸ“Š Smart Data Processing**: Converts CSV insurance data into semantic embeddings
- **ğŸ” Intelligent Retrieval**: Uses `all-MiniLM-L6-v2` for semantic search
- **ğŸ¤– AI-Powered Analysis**: Groq LLM provides expert insurance insights
- **ğŸ’» Modern UI**: Responsive Streamlit interface with custom styling
- **âš¡ Fast Performance**: Optimized vector search with ChromaDB
- **ğŸ›¡ï¸ Error Handling**: Robust retry logic and error management

## ğŸ—ï¸ System Architecture

```
CSV Data â†’ Vector Processing â†’ ChromaDB Storage â†’ RAG Pipeline â†’ Streamlit UI
```

## ğŸ“‹ Prerequisites

- Python 3.8+
- Groq API Key
- Insurance dataset in CSV format

## ğŸš€ Quick Start

### 1. Installation

```bash
git clone <your-repo-url>
cd auto-insurance-rag
pip install -r requirements.txt
```

### 2. Environment Setup

Create a `.env` file:
```env
GROQ_API_KEY=your_groq_api_key_here
```

### 3. Prepare Your Data

Place your insurance CSV file in the project directory. Expected columns:
- `policy_number`, `age`, `policy_state`, `policy_annual_premium`
- `insured_occupation`, `insured_education_level`, `incident_type`
- `total_claim_amount`, `fraud_reported`, etc.

### 4. Run the System

```bash
# Step 1: Convert CSV to vectors
python csv_to_vector.py

# Step 2: Test retrieval (optional)
python rag.py

# Step 3: Launch the app
streamlit run app.py
```

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ csv_to_vector.py      # Data processing & embedding generation
â”œâ”€â”€ rag.py               # RAG pipeline testing
â”œâ”€â”€ app.py               # Streamlit web application
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .env                 # Environment variables
â”œâ”€â”€ chroma_store/        # ChromaDB vector database
â”œâ”€â”€ static/              # Static files (new)
â”‚   â””â”€â”€ script.js        # JavaScript for frontend polish (new)
â””â”€â”€ README.md            # Project documentation         # This file
```

## ğŸ”§ File Details

### `csv_to_vector.py`
**Purpose**: Converts insurance CSV data into vector embeddings

**Key Functions**:
- Loads and processes insurance CSV data
- Creates meaningful text chunks from structured data
- Generates embeddings using `all-MiniLM-L6-v2`
- Stores vectors and metadata in ChromaDB

**Usage**:
```python
# Processes your CSV and creates embeddings
python csv_to_vector.py
```

### `rag.py`
**Purpose**: RAG pipeline for testing and querying

**Key Functions**:
- Embeds user queries
- Retrieves relevant insurance cases
- Calls Groq LLM for analysis
- Returns formatted insights

**Usage**:
```python
# Test your RAG system
python rag.py
```

### `app.py`
**Purpose**: Streamlit web interface

**Key Features**:
- Professional UI with custom CSS
- Real-time query processing
- Error handling and retry logic
- Responsive design
- Interactive forms and results display

## ğŸ¯ Example Queries

Try these queries in the application:

- **"What age groups have the lowest auto insurance premiums?"**
- **"Which occupations have the highest claim rates?"**
- **"How does education level affect insurance costs?"**
- **"What incidents involved bodily injury in specific cities?"**
- **"Which vehicle types have the most expensive claims?"**

## ğŸ“Š Data Processing Flow

### 1. CSV to Vector Conversion
```python
# Example chunk creation
chunk = f"Policy {policy_number} issued in {state} with premium ${premium}. "
       f"Customer: {age}-year-old {occupation}, education: {education}. "
       f"Incident: {incident_type}, claim amount: ${claim_amount}"
```

### 2. Embedding Generation
- Uses `sentence-transformers/all-MiniLM-L6-v2`
- Creates 384-dimensional vectors
- Stores with rich metadata

### 3. Retrieval Process
- Query embedding â†’ Similarity search
- Top-k relevant cases retrieved
- Context enriched with metadata

### 4. LLM Analysis
- Groq's `llama3-8b-8192` model
- Specialized insurance analysis prompts
- Data-driven insights and recommendations

## âš™ï¸ Configuration

### Model Settings
```python
EMBEDDING_MODEL = "all-MiniLM-L6-v2"
LLM_MODEL = "llama3-8b-8192"
TEMPERATURE = 0.3
MAX_TOKENS = 1000
TOP_K_RESULTS = 5
```

### ChromaDB Settings
```python
COLLECTION_NAME = "insurance_claims"
PERSIST_DIRECTORY = "chroma_store"
```

## ğŸ” API Reference

### Key Functions

**`embed_query(query: str) -> List[float]`**
- Converts text query to embedding vector

**`retrieve_context(query_embedding: List[float], n_results: int) -> Dict`**
- Retrieves similar insurance cases from vector database

**`generate_analysis(context: str, query: str) -> str`**
- Generates AI-powered insurance analysis

## ğŸ› ï¸ Customization

### Adding New Data Sources
1. Modify chunk creation in `csv_to_vector.py`
2. Update metadata fields
3. Adjust prompt templates in `app.py`

### Changing Models
```python
# In csv_to_vector.py and rag.py
embed_model = SentenceTransformer("your-preferred-model")

# In app.py
"model": "your-preferred-groq-model"
```

### UI Customization
- Modify CSS in `app.py`
- Update Streamlit components
- Add new visualizations

## ğŸ“ˆ Performance Metrics

- **Embedding Speed**: ~100 records/second
- **Query Response**: 1.5-3 seconds average
- **Vector Search**: Sub-second latency
- **Model Accuracy**: High relevance with insurance-specific prompts

## ğŸ”§ Troubleshooting

### Common Issues

**1. Empty Retrieval Results**
```python
# Check collection status
print(f"Collection count: {collection.count()}")
```

**2. API Key Errors**
- Verify `.env` file exists
- Check API key validity
- Ensure proper environment loading

**3. Model Loading Issues**
- Check internet connection
- Verify model name spelling
- Clear model cache if needed

**4. ChromaDB Errors**
- Delete `chroma_store` folder and regenerate
- Check file permissions
- Verify disk space

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ¯ Future Enhancements

- [ ] PDF document processing
- [ ] Multi-language support
- [ ] Advanced analytics dashboard
- [ ] Real-time data sync
- [ ] Voice query support
- [ ] Mobile-responsive design
- [ ] Batch query processing
- [ ] Custom model fine-tuning


---

**Built with â¤ï¸ using RAG, ChromaDB, and Streamlit**

*Transform your insurance data into intelligent insights!* ğŸš€